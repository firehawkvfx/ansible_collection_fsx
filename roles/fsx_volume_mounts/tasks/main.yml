---
# tasks file for fsx_volume_mounts

- name: test connection and permissions
  debug:
    msg: "connection established"
  tags:
  - local_install
  - cloud_install

- name: aquire vars from secrets path before using defaults for fsx mounts
  include_vars: "{{ item }}"
  with_first_found: "{{ fsx_vars_files_locs }}"
  tags:
  - always

- name: exports
  debug:
    var: item
  with_items: "{{ exports }}"
  when: destroy == false
  tags:
  - local_install
  - cloud_install

- name: exports
  package:
    name: jq
  tags:
  - always
  vars:
    ansible_python_interpreter: "{{ package_python_interpreter }}"

- name: Check aws sts get-caller-identity
  shell: |
    aws sts get-caller-identity
  become_user: deployuser
  args:
    executable: /bin/bash
  register: current_user
  connection: local
  when: destroy == false
  tags:
  - local_install
  - cloud_install

- name: Check whether aws fsx describe-file-systems contains the mount
  # command: grep -E "^\/export\/{{ item.pool_name }}\/{{ item.volume_name }}.*" /etc/exports
  shell: |
    aws fsx describe-file-systems | jq --slurp ".[0].FileSystems[] | select(.FileSystemId == \"{{ fsx_id }}\") | .LustreConfiguration.MountName" --raw-output
  become_user: deployuser
  args:
    executable: /bin/bash
  register: presence
  check_mode: no
  connection: local
  # ignore_errors: yes
  changed_when: no
  with_items: "{{ exports }}"
  when: destroy == false and fsx_id != 'none'
  tags:
  - local_install
  - cloud_install

- name: export existance test
  debug:
    var: item
  when: destroy == false and item.rc == 0
  with_items: "{{ presence.results }}"
  tags:
  - local_install
  - cloud_install

- name: export output always
  set_fact: fsx_exports="{{ presence.results }}"
  when: destroy == false
  tags:
  - local_install
  - cloud_install

# - name: export output always
#   set_fact: exported_fsx_mounts="{{item}}"
#   with_items: "{{ presence.results }}"
#   when: destroy == false
#   tags:
#   - local_install
#   - cloud_install

# # update fstab with valid mounts

# - hosts: "{{ variable_host | default('role_node_centos') }}"
#   remote_user: "{{ variable_user | default('centos') }}"
#   gather_facts: "{{ variable_gather_facts | default('false') }}"
#   become: true
#   vars_files:
#     - /deployuser/ansible/group_vars/all/vars
#     - vars/main.yml

- name: exports - debug
  debug:
    var: item
  with_items: "{{ exports }}"
  when: destroy == false
  tags:
  - local_install
  - cloud_install

- name: fsx exports to mount to this instance
  debug:
    var: item
  when: destroy == false
  with_items: 
  - "{{ fsx_exports }}"
  tags:
  - local_install
  - cloud_install

- name: create mount directories
  file: 
    path: "{{ item.item.path }}"
    state: directory
    owner: "{{ variable_user }}"
    group: "{{ variable_user }}"
    mode: u=rwX,g=rwX,o=rwX
  become: true
  when: destroy == false and item.rc == 0
  with_items: 
  - "{{ fsx_exports }}"
  tags:
  - local_install
  - cloud_install

- name: create bind1 directories
  file: 
    path: "{{ item.item.bind1 }}"
    state: directory
    owner: "{{ variable_user }}"
    group: "{{ variable_user }}"
    mode: u=rwX,g=rwX,o=rwX
  become: true
  when: destroy == false and item.item.bind1 and item.rc == 0
  with_items: 
  - "{{ fsx_exports }}"
  tags:
  - local_install
  - cloud_install

- name: create bind2 directories
  file: 
    path: "{{ item.item.bind2 }}"
    state: directory
    owner: "{{ variable_user }}"
    group: "{{ variable_user }}"
    mode: u=rwX,g=rwX,o=rwX
  become: true
  when: destroy == false and item.item.bind2 and item.rc == 0
  with_items: 
  - "{{ fsx_exports }}"
  tags:
  - local_install
  - cloud_install

- fail:
    msg: "{{ item.item.path }} is set to be present in exports dict but doesn't exist in /etc/exports"
  when: destroy == false and item.item.state == "present" and item.rc == 1
  with_items:
  - "{{ fsx_exports }}"
  tags:
  - local_install
  - cloud_install

- debug:
    msg: 'local onsite install will use different mounts'
  tags:
  - local_install

- name: Mount fsx Lustre volume from export - {{ fsx_ip }}@tcp:/{{ item.item.volume_name }} to /{{ item.item.volume_name }} If this fails, verify the lustre packages are installed and the system has been rebooted at least once after installation of packages.
  become: yes
  mount:
    fstype: lustre
    path: "/{{ item.item.volume_name }}"
    opts: "{{ item.item.mount_opts }}"
    # source must pull the ip from the fsx primary interface
    src: "{{ fsx_ip }}@tcp:/{{ item.stdout }}"
    state: "{{ ( destroy == false and item.item.path and item.rc == 0 and item.item.state == 'present') | ternary( 'mounted' , 'absent' ) }}"
  when: destroy == false
  with_items: "{{ fsx_exports }}"
  tags:
  - local_install

- name: exports check
  debug:
    var: item.bind2
  with_items: "{{ exports }}"
  when: destroy | bool
  tags:
  - local_install
  - cloud_install

- name: "bind master mounts to named paths.  /{{ item.item.volume_name }} to {{ item.item.bind2 }} bind2 references the absolute mount names such as /cloud_prod.  bind1 is relative site names such as /prod, which are not pushed from cloud to onsite since those paths should exist onsite from a high performance local mount"
  become: yes
  mount:
    fstype: none
    path: "{{ item.item.bind2 }}"
    opts: "x-systemd.requires=/{{ item.item.volume_name }},x-systemd.automount,bind,_netdev"
    src: "/{{ item.item.volume_name }}"
    # if the path exists, and it was found in the exports, then set to mounted, else remove.
    state: "{{ ( destroy == false and item.item.path and item.item.bind2 and item.rc == 0 and item.item.state == 'present' ) | ternary( 'mounted' , 'absent' ) }}"
  when: destroy == false
  with_items: "{{ fsx_exports }}"
  tags:
  - local_install

### Force removal of bind2 mounts when destroy is true.  currently the ansible command to unmount will hang if the connetion has been broken.
- debug:
    var: item
  when: destroy | bool
  with_items: "{{ exports }}"
  tags:
  - local_install

- name: check if bind2 mount points exist for forced removal
  command: timeout 5 mountpoint -q {{ item.bind2 }}
  become: yes
  register: volume_stat_bind2
  failed_when: False
  changed_when: False
  when: destroy | bool
  with_items: "{{ exports }}"
  tags:
  - local_install

- debug:
    var: item
  when: destroy | bool
  with_items: "{{ volume_stat_bind2.results }}"
  tags:
  - local_install

- name: report mount points
  debug:
    msg: "This is a mountpoint that will be removed"
  when: destroy | bool and ( item.rc == 0 or item.rc == 124 )
  with_items: "{{ volume_stat_bind2.results }}"
  tags:
  - local_install

- name: force unmount with shell when destroy is true.  bind must be removed before the hard mount - master.
  become: yes
  shell: |
    umount -l {{ item.item.bind2 }}
  when: destroy and ( item.rc == 0 or item.rc == 124 )
  with_items: "{{ volume_stat_bind2.results }}"
  tags:
  - local_install

### End force removal of mounts

- name: unmount when destroy is true.  bind must be removed before the hard mount - master.
  become: yes
  mount:
    path: "{{ item.bind2 }}"
    state: unmounted
  when: destroy | bool
  with_items: "{{ exports }}"
  tags:
  - local_install

- name: remove mounts from fstab when destroy is true.  bind must be removed before the hard mount - master.
  become: yes
  mount:
    path: "{{ item.bind2 }}"
    state: absent
  when: destroy | bool
  with_items: "{{ exports }}"
  tags:
  - local_install

### Force removal of master mounts.  currently the ansible command to unmount will hang if the connetion has been broken.

- name: check if master mount points exist for forced removal
  command: timeout 5 mountpoint -q {{ item.path }}
  become: yes
  register: volume_stat_path
  failed_when: False
  changed_when: False
  when: destroy | bool
  with_items: "{{ exports }}"
  tags:
  - local_install

- debug:
    var: item
  when: destroy | bool
  with_items: "{{ volume_stat_path.results }}"
  tags:
  - local_install

- name: report mount points.  if previous command timed out, then it was a mount point that is causing problems and should also be removed
  debug:
    msg: "This is a mountpoint that will be removed"
  when: destroy and ( item.rc == 0 or item.rc == 124 )
  with_items: "{{ volume_stat_path.results }}"
  tags:
  - local_install

- name: force unmount with shell when destroy is true.  bind must be removed before the hard mount - master.
  become: yes
  shell: |
    umount -l {{ item.item.path }}
  when: destroy and ( item.rc == 0 or item.rc == 124 )
  with_items: "{{ volume_stat_path.results }}"
  tags:
  - local_install

### End force removal of mounts

- name: unmount when destroy is true for Lustre fsx master on workstation.  this will not check the fsx instance, and use the mounts originally defined in your ebs settings in secrets
  become: yes
  mount:
    path: "{{ item.path }}"
    state: unmounted
  when: destroy | bool
  with_items: "{{ exports }}"
  tags:
  - local_install

- name: remove mounts from fstab when destroy is true for Lustre fsx master on workstation.  this will not check the fsx instance, and use the mounts originally defined in your ebs settings in secrets
  become: yes
  mount:
    path: "{{ item.path }}"
    state: absent
  when: destroy | bool
  with_items: "{{ exports }}"
  tags:
  - local_install


### cloud based mounts with ansible mount command

- name: fsx ip
  debug:
    msg: "{{ fsx_ip }}"
  when: destroy == false
  tags:
  - cloud_install

- name: insert/update block in in /etc/fstab on remote host for found exports using original unique pool and volume names - master
  become: yes
  mount:
    fstype: lustre
    path: "/{{ item.item.volume_name }}"
    opts: "{{ item.item.mount_opts }}"
    # source must pull the ip from the fsx primary interface
    src: "{{ fsx_ip }}@tcp:/{{ item.stdout }}"
    state: "{{ ( item.item.path and item.rc == 0 and item.item.state == 'present') | ternary( 'mounted' , 'absent' ) }}"
  when: destroy == false
  with_items: "{{ fsx_exports }}"
  tags:
  - cloud_install

- name: "bind1 master mounts to named paths.  /{{ item.item.volume_name }} to {{ item.item.bind1 }} bind1 references the absolute mount names such as /cloud_prod.  bind1 is relative site names such as /prod, which are not pushed from cloud to onsite since those paths should exist onsite from a high performance local mount"
  become: yes
  mount:
    fstype: none
    path: "{{ item.item.bind1 }}"
    opts: "x-systemd.requires=/{{ item.item.volume_name }},x-systemd.automount,bind,_netdev"
    src: "/{{ item.item.volume_name }}"
    # if the path exists, and it was found in the exports, then set to mounted, else remove.
    state: "{{ ( item.item.path and item.item.bind1 and item.rc == 0 and item.item.state == 'present' ) | ternary( 'mounted' , 'absent' ) }}"
  when: destroy == false
  with_items: "{{ fsx_exports }}"
  tags:
  - cloud_install

- name: "bind2 master mounts to named paths.  /{{ item.item.volume_name }} to {{ item.item.bind2 }} bind2 references the absolute mount names such as /cloud_prod.  bind1 is relative site names such as /prod, which are not pushed from cloud to onsite since those paths should exist onsite from a high performance local mount"
  become: yes
  mount:
    fstype: none
    path: "{{ item.item.bind2 }}"
    opts: "x-systemd.requires=/{{ item.item.volume_name }},x-systemd.automount,bind,_netdev"
    src: "/{{ item.item.volume_name }}"
    # if the path exists, and it was found in the exports, then set to mounted, else remove.
    state: "{{ ( item.item.path and item.item.bind2 and item.rc == 0 and item.item.state == 'present' ) | ternary( 'mounted' , 'absent' ) }}"
  when: destroy == false
  with_items: "{{ fsx_exports }}"
  tags:
  - cloud_install

# After fsx is mounted, the permissions of these previously created paths have changed, so we set it straight.
- name: ensure mount directories have correct permissions 
  file: 
    path: "{{ item.item.path }}"
    state: directory
    owner: "{{ variable_user }}"
    group: "{{ variable_user }}"
    mode: u=rwX,g=rwX,o=rwX
  become: true
  when: destroy == false and item.rc == 0
  with_items: 
  - "{{ fsx_exports }}"
  tags:
  - local_install
  - cloud_install

- name: ensure bind1 directories have correct permissions 
  file: 
    path: "{{ item.item.bind1 }}"
    state: directory
    owner: "{{ variable_user }}"
    group: "{{ variable_user }}"
    mode: u=rwX,g=rwX,o=rwX
  become: true
  when: destroy == false and item.item.bind1 and item.rc == 0
  with_items: 
  - "{{ fsx_exports }}"
  tags:
  - local_install
  - cloud_install

- name: ensure bind2 directories have correct permissions 
  file: 
    path: "{{ item.item.bind2 }}"
    state: directory
    owner: "{{ variable_user }}"
    group: "{{ variable_user }}"
    mode: u=rwX,g=rwX,o=rwX
  become: true
  when: destroy == false and item.item.bind2 and item.rc == 0
  with_items: 
  - "{{ fsx_exports }}"
  tags:
  - local_install
  - cloud_install
